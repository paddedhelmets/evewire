# Fittings Pipeline: From zkillboard to End-User

This document describes the complete pipeline for generating, importing, and using ship fittings in EVEWire, from raw zkillboard lossmail data all the way to end-user installation in the web UI.

## Overview

The fittings pipeline transforms raw killmail data from zkillboard into curated, verified ship fittings that end-users can browse, match against their assets, and import into EVE Online.

```
zkillboard lossmails → clustering → meta fits → database → web UI → in-game
```

## Stage 1: Clustering Artifacts

### Input Data
- **Source**: zkillboard API (https://zkillboard.com/)
- **Data**: ~3.26M ship lossmails across 286 ship types
- **Per fit**: Ship ID, modules (type_id, flag), character, timestamp, killmail_id

### Clustering Process

Location: `/home/genie/gt/evewire/crew/delve/career_research/clustering/`

**Database**: PostgreSQL with pgvector extension (`career_research` database)

**Key Files**:
- `cluster_all_ships.py` - Batch clustering script
- `cluster.py` - Core clustering logic using pgvector
- `analyze.py` - Extract canonical fits from clusters
- `reconcile_cluster_fits.py` - Generate reconciled fits with provenance

### Fit Embeddings

Each fitting is converted to a high-dimensional binary vector:
- **Dimension**: ~3500+ (one dimension per skill in EVE)
- **Format**: Binary vector (skill required = 1, not required = 0)
- **Storage**: `fit_vector` column in `fits` table (pgvector type)

```sql
-- Example: Check if a fit has an embedding
SELECT id, ship_id, fit_vector IS NOT NULL as has_embedding
FROM fits
WHERE ship_id = 670;  -- Capsule
```

### K-Means Clustering

For each ship type:
1. Select all fits with embeddings
2. Pick N random centers (default: 5)
3. Assign each fit to nearest center using cosine distance (`<=>` operator)
4. Store `cluster_id` (1-5) on each fit

```python
# From cluster.py
cur.execute("""
    WITH centers(center_id, cluster_num) AS (VALUES ...),
    distances AS (
        SELECT f.id, c.cluster_num,
               f.fit_vector <=> ref.fit_vector as distance
        FROM fits f
        CROSS JOIN centers c
        WHERE f.ship_id = %s
    )
    UPDATE fits f SET cluster_id = c.cluster_num
    FROM closest c WHERE f.id = c.id
""", [ship_id])
```

### Clustering Output

After clustering completes, the `fits` table contains:
- `id` - Fit primary key
- `ship_id` - Ship type ID
- `fit_vector` - Skill requirement embedding
- `cluster_id` - Assigned cluster (1-5)
- `killmail_id` - Source zkillboard killmail

### Canonical Fits

Location: `career_research/clustering/analyze.py`

**Definition**: A synthetic "most common" fit for each cluster, generated by taking the most popular module in each slot position.

```python
@dataclass
class CanonicalFit:
    ship_id: int
    ship_name: str
    cluster_id: int
    fit_count: int
    high_slots: List[Tuple[int, str, int]]  # (typeID, name, count)
    med_slots: List[Tuple[int, str, int]]
    low_slots: List[Tuple[int, str, int]]
    rig_slots: List[Tuple[int, str, int]]
    subsystem_slots: List[Tuple[int, str, int]]
    avg_similarity: float
```

**Generation**:
- For each slot position (0-7 for highs, etc.)
- Count module type_ids across all fits in cluster
- Select most common module as canonical
- Store usage count and percentage

**Pros**: Representative of cluster, deterministic
**Cons**: May not match any actual flown fit

### Reconciled Fits

Location: `career_research/clustering/reconcile_cluster_fits.py`

**Definition**: A consensus fit built from N actual sampled lossmails, with slot-by-slot provenance tracking.

**Generation**:
1. Sample N fits from cluster (default: 20)
2. For each slot position, count module occurrences
3. Select modules meeting threshold (40% of fits)
4. If multiple modules qualify, pick most common
5. Store all qualified modules as variations

**Output**: Markdown file with:
- EFT-format fitting
- Slot-by-slot breakdown with variations
- Provenance table linking to actual zkillboard killmails

```markdown
# Vexor - Cluster 1 (472 fits)

## Fitting
[Vexor, Meta Fit]
Damage Control II
...
Small Anti-EM Screen Reinforcer I

## Provenance
| Killmail | Date | Character |
|----------|------|-----------|
| [12345](https://zkillboard.com/kill/12345/) | 2024-01-15 | PilotOne |
| [12346](https://zkillboard.com/kill/12346/) | 2024-01-14 | PilotTwo |
```

**Pros**: Real sampled fits, full provenance traceable to zkillboard
**Cons**: Non-deterministic (different samples = different output)

## Stage 2: Import to EVEWire

Location: `/home/genie/gt/evewire/crew/delve/core/management/commands/`

### Import Method 1: Reconciled Fits

**Command**: `python manage.py import_meta_fits`

**Process**:
1. Scan `output/reconciled/*.md` for markdown files
2. Parse each file:
   - Extract ship name from title
   - Extract EFT fitting block
   - Extract provenance table
3. Parse EFT format into `FittingData`
4. Create `Fitting` record with:
   - `name` = "{ship_name} - Cluster {cluster_id}"
   - `ship_type_id` = from SDE lookup
   - `cluster_id` = from filename
   - `fit_count` = from header
   - `description` = formatted with provenance links
5. Create `FittingEntry` records for each module:
   - `slot_type` = 'high', 'med', 'low', 'rig', 'subsystem'
   - `position` = array index (0-based)
   - `module_type_id` = item typeID
   - `usage_count` = how many samples had this module
   - `usage_percentage` = count / sample_count

**Provenance in Description**:
```python
description = f"""Meta fit for {ship_name} (Cluster {cluster_id})

**Source**: EVEWire Career Research Module
**Method**: Cluster analysis of {sample_count} lossmails from zkillboard

**Example Lossmails**:
- [Killmail {killmail_id}]({zkillboard_url})
- [Killmail {killmail_id}]({zkillboard_url})
"""
```

### Import Method 2: Canonical Fits

**Command**: `python manage.py import_canonical_fittings`

**Process**:
1. Query `fits` table grouped by (ship_id, cluster_id)
2. Extract canonical fit using `ClusterAnalyzer`
3. Create `Fitting` and `FittingEntry` records
4. Include `avg_similarity` metric

**No provenance** - canonical fits are synthetic, not sampled from actual lossmails.

### Database Schema

**Fitting** (`core_doctrines_fitting`):
```python
class Fitting(models.Model):
    name = models.CharField(max_length=255)
    ship_type_id = models.IntegerField()
    cluster_id = models.IntegerField(null=True, blank=True)
    fit_count = models.IntegerField(null=True, blank=True)
    avg_similarity = models.FloatField(null=True, blank=True)
    description = models.TextField(blank=True)
    is_active = models.BooleanField(default=True)
    tags = models.JSONField(default=dict)
    skill_plans = models.ManyToManyField('core.SkillPlan')
    created_at = models.DateTimeField(auto_now_add=True)
```

**FittingEntry** (`core_doctrines_fittingentry`):
```python
class FittingEntry(models.Model):
    fitting = models.ForeignKey(Fitting, related_name='entries', on_delete=models.CASCADE)
    slot_type = models.CharField(max_length=12)  # 'high', 'med', 'low', 'rig', 'subsystem'
    position = models.IntegerField()
    module_type_id = models.IntegerField()
    module_name = models.CharField(max_length=255)
    usage_count = models.IntegerField(null=True, blank=True)
    usage_percentage = models.FloatField(null=True, blank=True)
```

**FittingMatch** (`core_doctrines_fittingmatch`):
```python
class FittingMatch(models.Model):
    character = models.ForeignKey('core.Character', on_delete=models.CASCADE)
    fitting = models.ForeignKey(Fitting, on_delete=models.CASCADE)
    ship_item_id = models.BigIntegerField()  # Asset item_id
    match_score = models.FloatField()
    missing_modules = models.JSONField(default=list)
    last_checked = models.DateTimeField(auto_now=True)
```

**ShoppingList** (`core_doctrines_shoppinglist`):
```python
class ShoppingList(models.Model):
    character = models.ForeignKey('core.Character', on_delete=models.CASCADE)
    fitting = models.ForeignKey(Fitting, on_delete=models.CASCADE)
    location_id = models.IntegerField()
    location_name = models.CharField(max_length=255)
    quantity = models.IntegerField(default=1)
    items = models.JSONField(default=list)  # [{'type_id': 123, 'name': 'Module', 'quantity': 2}]
    estimated_cost = models.DecimalField(max_digits=20, decimal_places=2, null=True)
```

## Stage 3: End-User Experience

### Web Interface

**Fittings List**: `/fittings/`
- Browse all imported fittings
- Filter by ship type, tags
- Show cluster metadata (fit_count, avg_similarity)

**Fitting Detail**: `/fittings/{fitting_id}/`

Template: `templates/core/fitting_detail.html`

**Displayed Information**:
1. Ship name and hull image
2. Cluster metadata:
   - Number of fits in cluster
   - Average similarity score
   - Source (zkillboard / manual)
3. Module layout by slot:
   - High slots (0-7)
   - Medium slots (0-7)
   - Low slots (0-7)
   - Rigs (0-3)
   - Subsystems (0-4)
4. Usage percentages for each module
5. Matching character assets:
   - Which characters have this ship fitted
   - Match score (0-1)
   - Missing modules
6. Export buttons:
   - EFT format
   - DNA format
   - XML format (EVE XML)

**Example**:
```html
<div class="fitting-header">
    <h1>Vexor - Cluster 1</h1>
    <div class="meta">
        <span>472 fits in cluster</span>
        <span>Avg similarity: 0.89</span>
    </div>
</div>

<div class="slots">
    <div class="high-slots">
        <div class="slot">
            <span class="position">H0</span>
            <span class="module">Ion Blaster II</span>
            <span class="usage">92%</span>
        </div>
        ...
    </div>
</div>
```

### Asset Matching

Location: `core/doctrines/services.py`

**Service**: `FittingMatcher`

**Process**:
1. Extract all fitted ships from character assets
2. For each ship, compare against each fitting
3. Calculate match score:
   ```
   score = (required_modules - missing_modules) / required_modules
   ```
4. Cache results in `FittingMatch` table
5. Display matching ships on fitting detail page

**Example**:
```python
# Character has 3 Vexors fitted
# 2 match at 95%+ score
# 1 match at 60% score (missing guns)
# Display: "2 matches found, 1 partial match"
```

### Shopping Lists

**Service**: `ShoppingListGenerator`

**Process**:
1. User selects fitting and quantity (N ships)
2. Select location (station/structure)
3. Calculate missing modules:
   - Check assets at location
   - Subtract already-owned modules
   - Multiply by N
4. Generate shopping list:
   - Type ID, name, quantity to buy
   - Estimated cost (from market)
5. Save to `ShoppingList` table
6. User can export list to in-game contract

## Stage 4: Import/Export Formats

Location: `core/fitting_formats/`

### Supported Formats

**EFT (EVE Fitting Tool)**:
```
[Vexor, New Vexor Fit]
Damage Control II
Ion Blaster II
Small Anti-EM Screen Reinforcer I
```

**DNA** (encoded string):
```
670:1;2456:2;2048:1;::[Fit Name]
```

**XML** (EVE multibuy):
```xml
<fittings>
  <fitting name="Fit Name">
    <shipType value="Vexor" />
    <hardware type="Damage Control II" slot="low 0" />
  </fitting>
</fittings>
```

### Unified API

**Import**:
```python
from core.fitting_formats import FittingImporter

# Auto-detect format
fitting = FittingImporter.import_from_string(eft_content)

# Specify format
fitting = FittingImporter.import_from_string(
    dna_content,
    format_name='dna',
    auto_detect=False
)
```

**Export**:
```python
from core.fitting_formats import FittingExporter

# Export to EFT
eft_string = FittingExporter.export_to_string(fitting, 'eft')

# Export to DNA
dna_string = FittingExporter.export_to_string(fitting, 'dna')
```

## Stage 5: Verification

### What to Verify

Aura's verification script should check:

1. **Module Type IDs**:
   - Verify each `module_type_id` in `FittingEntry` exists in SDE
   - Verify module is actually fittable (not a ship, not a skill)
   - Check module is appropriate for slot type (high vs med vs low)

2. **Slot Positions**:
   - Verify position indices are within valid range (0-7 for highs/meds/lows)
   - Verify position matches flag order from original lossmail
   - Check for duplicate positions

3. **Zkillboard Links**:
   - Parse URLs from `Fitting.description`
   - Verify each URL resolves to a valid killmail
   - Verify killmail contains the expected ship and modules

4. **Cluster Metadata**:
   - Verify `fit_count` matches actual fits in cluster
   - Verify `avg_similarity` is between 0-1
   - Verify `cluster_id` exists in source data

5. **EFT Export**:
   - Generate EFT string from database
   - Parse back with `FittingImporter`
   - Verify all modules match original

### Verification Queries

```sql
-- Check for invalid type IDs
SELECT fe.module_type_id, fe.module_name, fe.fitting_id
FROM core_doctrines_fittingentry fe
LEFT JOIN sde.invtypes t ON t.type_id = fe.module_type_id
WHERE t.type_id IS NULL;

-- Check for duplicate slot positions
SELECT fitting_id, slot_type, position, COUNT(*) as count
FROM core_doctrines_fittingentry
GROUP BY fitting_id, slot_type, position
HAVING COUNT(*) > 1;

-- Check fittings without cluster metadata
SELECT id, name, ship_type_id
FROM core_doctrines_fitting
WHERE cluster_id IS NULL AND fit_count IS NULL;

-- Verify fit counts match
SELECT
    f.id,
    f.name,
    f.cluster_id,
    f.fit_count,
    (SELECT COUNT(*) FROM career_research.public.fits
     WHERE ship_id = f.ship_type_id AND cluster_id = f.cluster_id) as actual_count
FROM core_doctrines_fitting f
WHERE f.cluster_id IS NOT NULL
  AND f.fit_count != (
    SELECT COUNT(*) FROM career_research.public.fits
    WHERE ship_id = f.ship_type_id AND cluster_id = f.cluster_id
);
```

## Stage 6: Running the Pipeline

### Step 1: Load SDE (if not already loaded)

```bash
cd career_research/sde
python load_sde.py
```

### Step 2: Cluster Ships

```bash
cd career_research/clustering

# Cluster all unclustered ships
python cluster_all_ships.py

# Cluster specific ship
python cluster_all_ships.py --ship-id 626

# Only ships with 100+ fits
python cluster_all_ships.py --min-fits 100

# Clear and re-run all
python cluster_all_ships.py --clear-all
```

### Step 3: Generate Reconciled Fits

```bash
cd career_research/clustering
python reconcile_cluster_fits.py
```

Output: `output/reconciled/*.md`

### Step 4: Import to EVEWire

```bash
cd /home/genie/gt/evewire/crew/delve

# Import reconciled fits (recommended - has provenance)
python manage.py import_meta_fits

# Or import canonical fits (synthetic)
python manage.py import_canonical_fittings
```

### Step 5: Verify

```bash
# Run Aura's verification script (when available)
python verify_fittings.py
```

## Historical Context

### EVEthing vs EVEWire

**EVEthing** (2013-2018):
- Original XML API tool for EVE Online asset management
- Discontinued after 2018 when CCP deprecated XML API
- Source: Reference notes in `EVENTHING_REFERENCE.md`

**EVEWire** (2024+):
- Spiritual successor using modern ESI API
- Django-based web application
- Multi-character aggregation
- Skill plan integration
- Vector-based fitting clustering

### Key Differences

| Feature | EVEthing | EVEWire |
|---------|----------|---------|
| API | XML (deprecated) | ESI (current) |
| Characters | Single-pilot | Multi-pilot aggregation |
| Fittings | Manual import only | Clustering + import |
| Skill Plans | None | Full integration |
| Assets | Basic view | Advanced matching |
| Technology | Unknown | Django + pgvector |

## Related Files

- `DISCOVERY.md` - Architecture decisions for EVEWire
- `EVENTHING_REFERENCE.md` - Original EVEthing feature reference
- `career_research/clustering/cluster.py` - Core clustering logic
- `career_research/clustering/analyze.py` - Canonical fit extraction
- `career_research/clustering/reconcile_cluster_fits.py` - Reconciled fit generation
- `core/doctrines/models.py` - Database models
- `core/doctrines/services.py` - Asset matching and shopping lists
- `core/fitting_formats/__init__.py` - Import/export formats
- `core/views/views_doctrines.py` - Web UI views
- `templates/core/fitting_detail.html` - Fitting detail page
